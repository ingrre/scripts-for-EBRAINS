{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting important metadata of tissue sample collections\n",
    "*Latest version 15 August 2022*\n",
    "\n",
    "With this notebook you can do the following:\n",
    "1. Query tissue sample collection metadata via the API for a particular dataset version(s)\n",
    "2. Save the information to a CSV file so that it can be used to create service links\n",
    "\n",
    "To be able to run the script, you need to the following requirements:\n",
    "- Python version >= 3.6\n",
    "- read and write permission to the KG via the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "from getpass import getpass\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "To interact with the API, you need an access token. To request a token, copy your token from the Knowledge Graph Editor or Query Builder (if you do not have access, request access via support@ebrains.eu).\n",
    "\n",
    "In case your token is expired, rerun the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = getpass(prompt='Please paste your token: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define where you want to extract information from\n",
    "\n",
    "First choose whether you want to extract tissue sample collection information from 1 or more dataset versions or from a project. \n",
    "\n",
    "1. Choose 1 to extract information from 1 dataset version. You will be asked to provide the UUID of the dataset version you are interested in.\n",
    "2. Choose 2 to extract information from multiple dataset versions. You will be asked to provide keyword(s) that exists in the title of all the dataset versions you are interested in. Make this as specific as possible to ensure that onlye the dataset versions of interest are queried.\n",
    "3. Choose 3 to extract information from all dataset versions associated with 1 project. You will be asked to provide the UUID of the project you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First identify the dataset version\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Ask the service the service links should be opened in.\n",
    "answer = input(\"Do you want to get the information from 1) one dataset version, 2) multiple dataset versions, or 3) all dataset versions of a project? \")\n",
    "if answer == \"1\":\n",
    "    dsv = input(\"What is the UUID of the dataset version? \")\n",
    "    print(f\"The UUID of the dataset is: {dsv}\")\n",
    "    output_path = os.path.join(cwd, dsv)\n",
    "\n",
    "elif answer == \"2\":\n",
    "    keywords = input(\"which keywords are in all titles of the dataset versions of interest? \")\n",
    "    print(f\"Query all dataset version with that contain {keywords} in the title\")\n",
    "    now = datetime.now()\n",
    "    output_path = os.path.join(cwd, now.strftime(\"%d%m%Y\"))\n",
    "\n",
    "elif answer == \"3\":\n",
    "    project = input(\"What is the UUID of the project? \")\n",
    "    print(f\"The UUID of the project is: {project}\")\n",
    "    output_path = os.path.join(cwd, project)\n",
    "    \n",
    "print(f\"The output folder is: {output_path}\")   \n",
    "\n",
    "if os.path.isdir(output_path):\n",
    "    print(\"\\nOutput folder already exists\")\n",
    "else:\n",
    "    print(\"\\nOutput folder does not exist, making folder\")        \n",
    "    os.mkdir(output_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the Knowledge Graph and extract information\n",
    "\n",
    "The following information will be extracted based on the dataset version UUID or keywords that you provided.\n",
    "- tsc name, tsc UUID, and internal identifier\n",
    "- linked file bundle name and UUID (if file bundles have been generated yet)\n",
    "- DOI of the dataset version\n",
    "- The URL of the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query will extract important information, such as the DOI of the dataset, the tissue sample collections and the linked subjects.\n",
    "if answer == '1':\n",
    "  query = {\n",
    "    \"@context\": {\n",
    "      \"@vocab\": \"https://core.kg.ebrains.eu/vocab/query/\",\n",
    "      \"query\": \"https://schema.hbp.eu/myQuery/\",\n",
    "      \"propertyName\": {\n",
    "        \"@id\": \"propertyName\",\n",
    "        \"@type\": \"@id\"\n",
    "      },\n",
    "      \"merge\": {\n",
    "        \"@type\": \"@id\",\n",
    "        \"@id\": \"merge\"\n",
    "      },\n",
    "      \"path\": {\n",
    "        \"@id\": \"path\",\n",
    "        \"@type\": \"@id\"\n",
    "      }\n",
    "    },\n",
    "    \"meta\": {\n",
    "      \"name\": \"get-dsv-specimen-fb\",\n",
    "      \"responseVocab\": \"https://schema.hbp.eu/myQuery/\",\n",
    "      \"type\": \"https://openminds.ebrains.eu/core/DatasetVersion\"\n",
    "    },\n",
    "    \"structure\": [\n",
    "      {\n",
    "        \"propertyName\": \"query:id\",\n",
    "        \"path\": \"@id\",\n",
    "        \"required\": True,\n",
    "        \"filter\": {\n",
    "          \"op\": \"CONTAINS\",\n",
    "          \"value\": dsv\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"propertyName\": \"query:digitalIdentifier\",\n",
    "        \"path\": \"https://openminds.ebrains.eu/vocab/digitalIdentifier\",\n",
    "        \"structure\": {\n",
    "          \"propertyName\": \"query:identifier\",\n",
    "          \"path\": \"https://openminds.ebrains.eu/vocab/identifier\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"propertyName\": \"query:repository\",\n",
    "        \"path\": \"https://openminds.ebrains.eu/vocab/repository\",\n",
    "        \"structure\": {\n",
    "          \"propertyName\": \"query:IRI\",\n",
    "          \"path\": \"https://openminds.ebrains.eu/vocab/IRI\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"propertyName\": \"query:studiedSpecimen\",\n",
    "        \"path\": \"https://openminds.ebrains.eu/vocab/studiedSpecimen\",\n",
    "        \"required\": True,\n",
    "        \"structure\": [\n",
    "          {\n",
    "            \"propertyName\": \"query:id\",\n",
    "            \"path\": \"@id\",\n",
    "            \"required\": True\n",
    "          },\n",
    "          {\n",
    "            \"propertyName\": \"query:lookupLabel\",\n",
    "            \"path\": \"https://openminds.ebrains.eu/vocab/lookupLabel\",\n",
    "            \"required\": True\n",
    "          },\n",
    "          {\n",
    "            \"propertyName\": \"query:internalIdentifier\",\n",
    "            \"path\": \"https://openminds.ebrains.eu/vocab/internalIdentifier\"\n",
    "          },\n",
    "          {\n",
    "            \"propertyName\": \"query:type\",\n",
    "            \"path\": \"@type\",\n",
    "            \"required\": True,\n",
    "            \"filter\": {\n",
    "              \"op\": \"CONTAINS\",\n",
    "              \"value\": \"TissueSampleCollection\"\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "          \"propertyName\": \"query:studiedState\",\n",
    "          \"path\": \"https://openminds.ebrains.eu/vocab/studiedState\",\n",
    "          \"structure\": [\n",
    "            {\n",
    "              \"propertyName\": \"query:id\",\n",
    "              \"path\": \"@id\"\n",
    "            },\n",
    "            {\n",
    "              \"propertyName\": \"query:lookupLabel\",\n",
    "              \"path\": \"https://openminds.ebrains.eu/vocab/lookupLabel\"\n",
    "            },\n",
    "            {\n",
    "              \"propertyName\": \"query:descendedFromFile\",\n",
    "              \"path\": {\n",
    "                \"@id\": \"https://openminds.ebrains.eu/vocab/descendedFrom\",\n",
    "                \"reverse\": True\n",
    "              },\n",
    "              \"structure\": [\n",
    "                {\n",
    "                  \"propertyName\": \"query:id\",\n",
    "                  \"path\": \"@id\"\n",
    "                },\n",
    "                {\n",
    "                  \"propertyName\": \"query:name\",\n",
    "                  \"path\": \"https://openminds.ebrains.eu/vocab/name\"\n",
    "                }\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"propertyName\": \"query:descendedFromSubject\",\n",
    "              \"path\": \"https://openminds.ebrains.eu/vocab/descendedFrom\",\n",
    "              \"structure\": [\n",
    "                {\n",
    "                \"propertyName\": \"query:id\",\n",
    "                \"path\": \"@id\"\n",
    "                },\n",
    "                {\n",
    "                \"propertyName\": \"query:lookupLabel\",\n",
    "                \"path\": \"https://openminds.ebrains.eu/vocab/lookupLabel\"\n",
    "                },\n",
    "                {\n",
    "                \"propertyName\": \"query:studiedState\",\n",
    "                \"path\": {\n",
    "                  \"@id\": \"https://openminds.ebrains.eu/vocab/studiedState\",\n",
    "                  \"reverse\": True\n",
    "                },\n",
    "                \"structure\": [\n",
    "                  {\n",
    "                    \"propertyName\": \"query:id\",\n",
    "                    \"path\": \"@id\"\n",
    "                  },\n",
    "                  {\n",
    "                    \"propertyName\": \"query:internalIdentifier\",\n",
    "                    \"path\": \"https://openminds.ebrains.eu/vocab/internalIdentifier\"\n",
    "                  }\n",
    "                ]\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "elif answer == '2':\n",
    "  query = {\n",
    "  \"@context\": {\n",
    "    \"@vocab\": \"https://core.kg.ebrains.eu/vocab/query/\",\n",
    "    \"query\": \"https://schema.hbp.eu/myQuery/\",\n",
    "    \"propertyName\": {\n",
    "      \"@id\": \"propertyName\",\n",
    "      \"@type\": \"@id\"\n",
    "    },\n",
    "    \"merge\": {\n",
    "      \"@type\": \"@id\",\n",
    "      \"@id\": \"merge\"\n",
    "    },\n",
    "    \"path\": {\n",
    "      \"@id\": \"path\",\n",
    "      \"@type\": \"@id\"\n",
    "    }\n",
    "  },\n",
    "  \"meta\": {\n",
    "    \"name\": \"get-dsv-specimen-fb\",\n",
    "    \"responseVocab\": \"https://schema.hbp.eu/myQuery/\",\n",
    "    \"type\": \"https://openminds.ebrains.eu/core/DatasetVersion\"\n",
    "  },\n",
    "  \"structure\": [\n",
    "    {\n",
    "      \"propertyName\": \"query:id\",\n",
    "      \"path\": \"@id\",\n",
    "      \"required\": True\n",
    "    },\n",
    "    {\n",
    "      \"propertyName\": \"query:digitalIdentifier\",\n",
    "      \"path\": \"https://openminds.ebrains.eu/vocab/digitalIdentifier\",\n",
    "      \"required\": True,\n",
    "      \"structure\": {\n",
    "        \"propertyName\": \"query:identifier\",\n",
    "        \"path\": \"https://openminds.ebrains.eu/vocab/identifier\",\n",
    "        \"required\": True\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"propertyName\": \"query:repository\",\n",
    "      \"path\": \"https://openminds.ebrains.eu/vocab/repository\",\n",
    "      \"required\": True,\n",
    "      \"structure\": {\n",
    "        \"propertyName\": \"query:IRI\",\n",
    "        \"path\": \"https://openminds.ebrains.eu/vocab/IRI\",\n",
    "        \"required\": True\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"propertyName\": \"query:shortName\",\n",
    "      \"path\": \"https://openminds.ebrains.eu/vocab/shortName\",\n",
    "      \"filter\": {\n",
    "        \"op\": \"CONTAINS\",\n",
    "        \"value\": keywords\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"propertyName\": \"query:studiedSpecimen\",\n",
    "      \"path\": \"https://openminds.ebrains.eu/vocab/studiedSpecimen\",\n",
    "      \"required\": True,\n",
    "      \"structure\": [\n",
    "        {\n",
    "          \"propertyName\": \"query:id\",\n",
    "          \"path\": \"@id\",\n",
    "          \"required\": True\n",
    "        },\n",
    "        {\n",
    "          \"propertyName\": \"query:lookupLabel\",\n",
    "          \"path\": \"https://openminds.ebrains.eu/vocab/lookupLabel\",\n",
    "          \"required\": True\n",
    "        },\n",
    "        {\n",
    "          \"propertyName\": \"query:internalIdentifier\",\n",
    "          \"path\": \"https://openminds.ebrains.eu/vocab/internalIdentifier\"\n",
    "        },\n",
    "        {\n",
    "          \"propertyName\": \"query:type\",\n",
    "          \"path\": \"@type\",\n",
    "          \"required\": True,\n",
    "          \"filter\": {\n",
    "            \"op\": \"CONTAINS\",\n",
    "            \"value\": \"TissueSampleCollection\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"propertyName\": \"query:studiedState\",\n",
    "          \"path\": \"https://openminds.ebrains.eu/vocab/studiedState\",\n",
    "          \"structure\": [\n",
    "            {\n",
    "              \"propertyName\": \"query:id\",\n",
    "              \"path\": \"@id\"\n",
    "            },\n",
    "            {\n",
    "              \"propertyName\": \"query:lookupLabel\",\n",
    "              \"path\": \"https://openminds.ebrains.eu/vocab/lookupLabel\"\n",
    "            },\n",
    "            {\n",
    "              \"propertyName\": \"query:descendedFromFile\",\n",
    "              \"path\": {\n",
    "                \"@id\": \"https://openminds.ebrains.eu/vocab/descendedFrom\",\n",
    "                \"reverse\": True\n",
    "              },\n",
    "              \"structure\": [\n",
    "                {\n",
    "                  \"propertyName\": \"query:id\",\n",
    "                  \"path\": \"@id\"\n",
    "                },\n",
    "                {\n",
    "                  \"propertyName\": \"query:name\",\n",
    "                  \"path\": \"https://openminds.ebrains.eu/vocab/name\"\n",
    "                }\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"propertyName\": \"query:descendedFromSubject\",\n",
    "              \"path\": \"https://openminds.ebrains.eu/vocab/descendedFrom\",\n",
    "              \"structure\": [\n",
    "                {\n",
    "                \"propertyName\": \"query:id\",\n",
    "                \"path\": \"@id\"\n",
    "                },\n",
    "                {\n",
    "                \"propertyName\": \"query:lookupLabel\",\n",
    "                \"path\": \"https://openminds.ebrains.eu/vocab/lookupLabel\"\n",
    "                },\n",
    "                {\n",
    "                \"propertyName\": \"query:studiedState\",\n",
    "                \"path\": {\n",
    "                  \"@id\": \"https://openminds.ebrains.eu/vocab/studiedState\",\n",
    "                  \"reverse\": True\n",
    "                },\n",
    "                \"structure\": [\n",
    "                  {\n",
    "                    \"propertyName\": \"query:id\",\n",
    "                    \"path\": \"@id\"\n",
    "                  },\n",
    "                  {\n",
    "                    \"propertyName\": \"query:internalIdentifier\",\n",
    "                    \"path\": \"https://openminds.ebrains.eu/vocab/internalIdentifier\"\n",
    "                  }\n",
    "                ]\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "elif answer == '3':\n",
    "  query = {\n",
    "  \"@context\": {\n",
    "    \"@vocab\": \"https://core.kg.ebrains.eu/vocab/query/\",\n",
    "    \"query\": \"https://schema.hbp.eu/myQuery/\",\n",
    "    \"propertyName\": {\n",
    "      \"@id\": \"propertyName\",\n",
    "      \"@type\": \"@id\"\n",
    "    },\n",
    "    \"path\": {\n",
    "      \"@id\": \"path\",\n",
    "      \"@type\": \"@id\"\n",
    "    }\n",
    "  },\n",
    "  \"meta\": {\n",
    "    \"type\": \"https://openminds.ebrains.eu/core/Project\",\n",
    "    \"responseVocab\": \"https://schema.hbp.eu/myQuery/\"\n",
    "  },\n",
    "  \"structure\": [\n",
    "    {\n",
    "      \"propertyName\": \"query:fullName\",\n",
    "      \"path\": \"https://openminds.ebrains.eu/vocab/fullName\"\n",
    "    },\n",
    "    {\n",
    "      \"propertyName\": \"query:id\",\n",
    "      \"path\": \"@id\",\n",
    "      \"required\": True,\n",
    "      \"filter\": {\n",
    "        \"op\": \"CONTAINS\",\n",
    "        \"value\": project\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"propertyName\": \"query:hasResearchProducts\",\n",
    "      \"path\": \"https://openminds.ebrains.eu/vocab/hasResearchProducts\",\n",
    "      \"structure\": [\n",
    "        {\n",
    "          \"propertyName\": \"query:id\",\n",
    "          \"path\": \"@id\"\n",
    "        },\n",
    "        {\n",
    "          \"propertyName\": \"query:shortName\",\n",
    "          \"path\": \"https://openminds.ebrains.eu/vocab/shortName\"\n",
    "        },\n",
    "        {\n",
    "          \"propertyName\": \"query:digitalIdentifier\",\n",
    "          \"path\": \"https://openminds.ebrains.eu/vocab/digitalIdentifier\",\n",
    "          \"structure\": {\n",
    "            \"propertyName\": \"query:identifier\",\n",
    "            \"path\": \"http://schema.org/identifier\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"propertyName\": \"query:repository\",\n",
    "          \"path\": \"https://openminds.ebrains.eu/vocab/repository\",\n",
    "          \"structure\": {\n",
    "            \"propertyName\": \"query:IRI\",\n",
    "            \"path\": \"https://openminds.ebrains.eu/vocab/IRI\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"propertyName\": \"query:studiedSpecimen\",\n",
    "          \"path\": \"https://openminds.ebrains.eu/vocab/studiedSpecimen\",\n",
    "          \"required\": True,\n",
    "          \"structure\": [\n",
    "            {\n",
    "              \"propertyName\": \"query:id\",\n",
    "              \"path\": \"@id\",\n",
    "              \"required\": True\n",
    "            },\n",
    "            {\n",
    "              \"propertyName\": \"query:lookupLabel\",\n",
    "              \"path\": \"https://openminds.ebrains.eu/vocab/lookupLabel\",\n",
    "              \"required\": True\n",
    "            },\n",
    "            {\n",
    "              \"propertyName\": \"query:internalIdentifier\",\n",
    "              \"path\": \"https://openminds.ebrains.eu/vocab/internalIdentifier\"\n",
    "            },\n",
    "            {\n",
    "              \"propertyName\": \"query:type\",\n",
    "              \"path\": \"@type\",\n",
    "              \"required\": True,\n",
    "              \"filter\": {\n",
    "                \"op\": \"CONTAINS\",\n",
    "                \"value\": \"TissueSampleCollection\"\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "            \"propertyName\": \"query:studiedState\",\n",
    "            \"path\": \"https://openminds.ebrains.eu/vocab/studiedState\",\n",
    "            \"structure\": [\n",
    "              {\n",
    "                \"propertyName\": \"query:id\",\n",
    "                \"path\": \"@id\"\n",
    "              },\n",
    "              {\n",
    "                \"propertyName\": \"query:lookupLabel\",\n",
    "                \"path\": \"https://openminds.ebrains.eu/vocab/lookupLabel\"\n",
    "              },\n",
    "              {\n",
    "                \"propertyName\": \"query:descendedFromFile\",\n",
    "                \"path\": {\n",
    "                  \"@id\": \"https://openminds.ebrains.eu/vocab/descendedFrom\",\n",
    "                  \"reverse\": True\n",
    "                },\n",
    "                \"structure\": [\n",
    "                  {\n",
    "                    \"propertyName\": \"query:id\",\n",
    "                    \"path\": \"@id\"\n",
    "                  },\n",
    "                  {\n",
    "                    \"propertyName\": \"query:name\",\n",
    "                    \"path\": \"https://openminds.ebrains.eu/vocab/name\"\n",
    "                  }\n",
    "                ]\n",
    "              },\n",
    "              {\n",
    "                \"propertyName\": \"query:descendedFromSubject\",\n",
    "                \"path\": \"https://openminds.ebrains.eu/vocab/descendedFrom\",\n",
    "                \"structure\": [\n",
    "                  {\n",
    "                  \"propertyName\": \"query:id\",\n",
    "                  \"path\": \"@id\"\n",
    "                  },\n",
    "                  {\n",
    "                  \"propertyName\": \"query:lookupLabel\",\n",
    "                  \"path\": \"https://openminds.ebrains.eu/vocab/lookupLabel\"\n",
    "                  },\n",
    "                  {\n",
    "                  \"propertyName\": \"query:studiedState\",\n",
    "                  \"path\": {\n",
    "                    \"@id\": \"https://openminds.ebrains.eu/vocab/studiedState\",\n",
    "                    \"reverse\": True\n",
    "                  },\n",
    "                  \"structure\": [\n",
    "                    {\n",
    "                      \"propertyName\": \"query:id\",\n",
    "                      \"path\": \"@id\"\n",
    "                    },\n",
    "                    {\n",
    "                      \"propertyName\": \"query:internalIdentifier\",\n",
    "                      \"path\": \"https://openminds.ebrains.eu/vocab/internalIdentifier\"\n",
    "                    }\n",
    "                  ]\n",
    "                  }\n",
    "                ]\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the info based on what is defined in the query\n",
    "def getInfo(token, stage=\"IN_PROGRESS\"):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    token : string \n",
    "        Authentication token to access data and metadata in the KGE via the API\n",
    "    stage : string\n",
    "        Stage the data are in, e.g. \"RELEASED\", \"IN_PROGRESS\". Default is \"IN_PROGRESS\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dictionary\n",
    "        All data that was specified in the query\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    headers = {\n",
    "                \"Authorization\": \"Bearer \" + token\n",
    "                }\n",
    "\n",
    "    url = \"https://core.kg.ebrains.eu/v3-beta/queries/?vocab=https://schema.hbp.eu/myQuery/&stage={}\"\n",
    "    response = requests.post(url.format(stage), json=query, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(response, \"OK!\" )\n",
    "        data = response.json()\n",
    "    elif response.status_code == 401:\n",
    "        print(response, \"Token not valid, authorisation not successful\")\n",
    "        return\n",
    "    else:\n",
    "        print(response)\n",
    "        return\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute the query we need to define the stage of release. If the data is under embargo, the stage is \"IN_PROGRESS\", if the data has already been released, the stage is \"RELEASED\". The default setting is \"in progress\" as it will find both released and ongoing curated metadata.\n",
    "\n",
    "**Note:** the data should already be released, since file bundles are not created when datasets are under embargo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stage\n",
    "stage = \"IN_PROGRESS\"\n",
    "\n",
    "# Execute the getInfo function\n",
    "result = getInfo(token, stage=stage)\n",
    "\n",
    "if len(result) == 0:\n",
    "    print(\"No metadata extracted \\nRefresh token and run the cells again!\")   \n",
    "elif len(result[\"data\"]) == 0:\n",
    "    print(\"No data could be extracted. The required metadata defined in the query does not match the information in the dataset versions or project. Check if the information is available (see list above)\")\n",
    "else:\n",
    "    # Save relevant metadata\n",
    "    if answer == '1':\n",
    "        tsc_list = []\n",
    "        for i in range(len(result[\"data\"][0][\"studiedSpecimen\"])):\n",
    "            tsc_list.append(result[\"data\"][0][\"studiedSpecimen\"][i])\n",
    "            if result[\"data\"][0][\"digitalIdentifier\"] == []:\n",
    "                tsc_list[i]['DOI'] = \"N/A\"\n",
    "            else:\n",
    "                tsc_list[i]['DOI'] =  result[\"data\"][0][\"digitalIdentifier\"][0][\"identifier\"]\n",
    "            if \"repository\" in result[\"data\"][0]:\n",
    "                tsc_list[i]['Repo'] = result[\"data\"][0][\"repository\"][0][\"IRI\"]\n",
    "            else:\n",
    "                tsc_list[i]['Repo'] = \"N/A\"\n",
    "            tsc_list[i]['dsv_uuid'] = result[\"data\"][0][\"id\"].split(\"/\")[-1]\n",
    "        print('\\nNumber of tissue sample collections in this dataset: ' + str(len(tsc_list)))\n",
    "        print('\\nDOI of this dataset: ' + tsc_list[0][\"DOI\"])\n",
    "        print('\\nRepository of this dataset: ' + tsc_list[0]['Repo'])\n",
    "    elif answer == '2':\n",
    "        print(\"Number of dataset version found that match the keywords: \" + str(len(result['data'])))\n",
    "        tsc_list = []\n",
    "        count = 0\n",
    "        for i in range(len(result['data'])):\n",
    "            \n",
    "            if len(result[\"data\"][i][\"studiedSpecimen\"]) > 1:\n",
    "                for ii in range(len(result[\"data\"][i][\"studiedSpecimen\"])):\n",
    "                    tsc_list.append(result[\"data\"][i][\"studiedSpecimen\"][ii])\n",
    "                    if result[\"data\"][0][\"digitalIdentifier\"] == []:\n",
    "                        tsc_list[count]['DOI'] = \"N/A\"\n",
    "                    else:\n",
    "                        tsc_list[count]['DOI'] = result[\"data\"][i][\"digitalIdentifier\"][0][\"identifier\"]\n",
    "                    if \"repository\" in result[\"data\"][0]:\n",
    "                        tsc_list[count]['Repo'] = result[\"data\"][i][\"repository\"][0][\"IRI\"]\n",
    "                    else:\n",
    "                        tsc_list[count]['Repo'] = \"N/A\"\n",
    "                    tsc_list[count]['dsv_uuid'] = result[\"data\"][i][\"id\"].split(\"/\")[-1]\n",
    "                    count += 1\n",
    "            else:\n",
    "                tsc_list.append(result[\"data\"][i][\"studiedSpecimen\"][0])\n",
    "                if result[\"data\"][0][\"digitalIdentifier\"] == []:\n",
    "                    tsc_list[count]['DOI'] = \"N/A\"\n",
    "                else:\n",
    "                    tsc_list[count]['DOI'] = result[\"data\"][i][\"digitalIdentifier\"][0][\"identifier\"]\n",
    "                if \"repository\" in result[\"data\"][0]:\n",
    "                    tsc_list[count]['Repo'] = result[\"data\"][i][\"repository\"][0][\"IRI\"]\n",
    "                else:\n",
    "                    tsc_list[count]['Repo'] = \"N/A\"\n",
    "                tsc_list[count]['dsv_uuid'] = result[\"data\"][i][\"id\"].split(\"/\")[-1]\n",
    "                count += 1\n",
    "    elif answer == '3':\n",
    "        print(\"Number of dataset versions in this project: \" + str(len(result[\"data\"][0][\"hasResearchProducts\"])))\n",
    "        tsc_list = []\n",
    "        count = 0\n",
    "        for i in range(len(result[\"data\"][0][\"hasResearchProducts\"])):\n",
    "            \n",
    "            if len(result[\"data\"][0][\"hasResearchProducts\"][i][\"studiedSpecimen\"]) > 1:\n",
    "                for ii in range(len(result[\"data\"][0][\"hasResearchProducts\"][i][\"studiedSpecimen\"])):\n",
    "                    tsc_list.append(result[\"data\"][0][\"hasResearchProducts\"][i][\"studiedSpecimen\"][ii])\n",
    "                    if result[\"data\"][0][\"hasResearchProducts\"][0][\"digitalIdentifier\"] == []:\n",
    "                        tsc_list[count]['DOI'] = \"N/A\"\n",
    "                    else:\n",
    "                        tsc_list[count]['DOI'] = result[\"data\"][0][\"hasResearchProducts\"][i][\"digitalIdentifier\"][0][\"identifier\"]\n",
    "                    if \"repository\" in result[\"data\"][0][\"hasResearchProducts\"][i]:\n",
    "                        tsc_list[count]['Repo'] = result[\"data\"][0][\"hasResearchProducts\"][i][\"repository\"][0][\"IRI\"]\n",
    "                    else:\n",
    "                        tsc_list[count]['Repo'] = \"N/A\"\n",
    "                    tsc_list[count]['dsv_uuid'] = result[\"data\"][0][\"hasResearchProducts\"][i][\"id\"].split(\"/\")[-1]\n",
    "                    count += 1\n",
    "            else:\n",
    "                tsc_list.append(result[\"data\"][0][\"hasResearchProducts\"][i][\"studiedSpecimen\"][0])\n",
    "                if result[\"data\"][0][\"hasResearchProducts\"][i][\"digitalIdentifier\"] == []:\n",
    "                    tsc_list[count]['DOI'] = \"N/A\"\n",
    "                else:\n",
    "                    tsc_list[count]['DOI'] = result[\"data\"][0][\"hasResearchProducts\"][i][\"digitalIdentifier\"][0][\"identifier\"]\n",
    "                if \"repository\" in result[\"data\"][0][\"hasResearchProducts\"][0]:\n",
    "                    tsc_list[count]['Repo'] = result[\"data\"][0][\"hasResearchProducts\"][i][\"repository\"][0][\"IRI\"]\n",
    "                else:\n",
    "                    tsc_list[count]['Repo'] = \"N/A\"\n",
    "                tsc_list[count]['dsv_uuid'] = result[\"data\"][0][\"hasResearchProducts\"][i][\"id\"].split(\"/\")[-1]\n",
    "                count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organise and save the metadata\n",
    "\n",
    "The metadata extracted by the query is now organised into an easier to read format and saved as a CSV file. The name of the CSV file is \"tsc_UUID-of-datasetVersion\" or \"tsc_list\", depending on whether the information applies to 1 or more dataset versions.\n",
    "\n",
    "For the organisation it is important that particular naming conventions are used.\n",
    "Each subject has a subjectID in the file name which needs to be used as the internal identifier of the subject. The internal identifier is used for the generation of file bundles and later also for the generation of regex patterns for the image service ingestion. The lookup label of the subject can be a user-defined name, but it is important that the lookup label for the tissue sample collection is an extension of this name. For example, if the subject is called \"A102\", the tissue sample collection should be called \"A102_tsc\". For the states of the subject and the tissue sample collection, the naming convention is \"lookupLabel_state-01\", so for the above example the state name is \"A102_state-01\" and \"A102_tsc_state-01\" for the subject and tissue sample collection, respectively. \n",
    "\n",
    "Note: Use the underscore to separate names and states, and dashes to separate elements within a name, e.g. sub-01, state-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract tissue sample collection information\n",
    "def extractInfo(tsc_list, file_extension):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    tsc_list : list \n",
    "        Nested list of tsc information\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pandas DataFrame\n",
    "        Overview table with extracted information\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    data = pd.DataFrame([])\n",
    "    for tsc in tsc_list:\n",
    "        if not \"descendedFromFile\" in tsc['studiedState'][0].keys():\n",
    "            fileBundle_name = \"\"\n",
    "            fileBundle_uuid = \"\"\n",
    "            regex_pattern = \"\"\n",
    "        else:\n",
    "            if tsc[\"studiedState\"][0][\"descendedFromFile\"] == []:\n",
    "                fileBundle_name = \"\"\n",
    "                fileBundle_uuid = \"\"\n",
    "                regex_pattern = \"\"\n",
    "            else:\n",
    "                fileBundle_name = tsc[\"studiedState\"][0][\"descendedFromFile\"][0][\"name\"]\n",
    "                fileBundle_uuid = tsc[\"studiedState\"][0][\"descendedFromFile\"][0][\"id\"].split(\"/\")[-1]\n",
    "                if file_extension == \"\":\n",
    "                    print(\"No file extension defined, add extension to the regex pattern yourself\")\n",
    "                    regex_pattern = fileBundle_name + \".*s[\\d]{1,3}\" + \"\\\\\"\n",
    "                else:\n",
    "                    regex_pattern = fileBundle_name + \".*s[\\d]{1,3}\\\\\" +  file_extension\n",
    "\n",
    "        # If only one DOI is available, use that one, otherwise concatenate all DOIs in one string\n",
    "        if isinstance(tsc[\"DOI\"], str):\n",
    "            DOI = tsc['DOI']\n",
    "        else:\n",
    "            DOI = '\\n'.join(tsc['DOI'])\n",
    "\n",
    "        data = data.append(pd.DataFrame({\"sub_name\" : tsc[\"studiedState\"][0][\"descendedFromSubject\"][0][\"studiedState\"][0][\"internalIdentifier\"],\n",
    "                        # \"sub_uuid\" : tsc[\"studiedState\"][0][\"descendedFromSubject\"][0][\"studiedState\"][0][\"id\"],\n",
    "                        \"tsc_name\" : tsc[\"lookupLabel\"],\n",
    "                        \"tsc_internalID\" : tsc[\"internalIdentifier\"],\n",
    "                        \"tsc_uuid\" : tsc[\"id\"].split(\"/\")[-1],\n",
    "                        \"tsc_state_uuid\" : tsc[\"studiedState\"][0][\"id\"].split(\"/\")[-1],\n",
    "                        \"bucket_name\" : \"img-\" + tsc[\"id\"].split(\"/\")[-1],\n",
    "                        \"collab_name\" : \"Image chunks for tsc \" + tsc[\"lookupLabel\"] +  \" for dataset version: \" + tsc[\"dsv_uuid\"],\n",
    "                        \"fileBundle_name\" : fileBundle_name,  \n",
    "                        \"fileBundle_uuid\" : fileBundle_uuid,\n",
    "                        \"regex_pattern\" : regex_pattern,\n",
    "                        \"DOI_dataset\" : DOI,\n",
    "                        \"repository\" : tsc['Repo'],\n",
    "                        \"viewer_link\" : \"Fill in the viewer link here\"},                \n",
    "                    index=[0]), \n",
    "                ignore_index=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset is well organised, we can extract the regex pattern for each tissue sample collection. The general idea is that each file contains the subject name (which is used in the regex pattern to create file bundles, e.g. H109), a section number (e.g. s001) and a file extention (e.g. '.tif'). If the files in the folder do not follow this naming convention (e.g. H109...s001.tif), the regex pattern in the cell above needs to be changed. The cell below will ask you to define the file extension of the files you want to create a task for (typically '.tif' for 2d images). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the extractInfo function\n",
    "file_extension = input(\"What is the file extension of the files that need to be ingested (e.g. '.tif'): \")\n",
    "tsc_data = extractInfo(tsc_list, file_extension)\n",
    "\n",
    "if answer == '1':\n",
    "    filename = os.path.join(output_path, 'tsc_' + dsv + '.csv')\n",
    "elif answer == '2':\n",
    "    filename = os.path.join(output_path, 'tsc_list' + '.csv')\n",
    "elif answer == '3':\n",
    "    filename = os.path.join(output_path, 'tsc_' + project + '.csv')\n",
    "# save the table locally in the current folder using the name \"tsc_UUID-of-dataset\"\n",
    "tsc_data.to_csv(filename, index = False, header=True)\n",
    "\n",
    "print(\"Done! File is saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tasks\n",
    "\n",
    "To be able to ingest the images, we first need to create a task. The cells below will use the extracted information to create a task for each tissue sample collection and saves it as a JSON file with the following naming convention: task_[filebundleName].json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build task instruction\n",
    "def build_task(source_url: str, input_filter: str, collab_name: str):\n",
    "    \n",
    "    task_definition = {\n",
    "                        \"description\": collab_name,\n",
    "                        \"definition\": {\n",
    "                            \"type\": \"ingest\",\n",
    "                            \"url\": source_url,\n",
    "                            \"two_d\": True,\n",
    "                            \"runtime_limit\":\"24h\",\n",
    "                            \"filter\": input_filter,\n",
    "                            # \"ingestion_parameters\":{\n",
    "                            #     \"is_stack\":False,\n",
    "                            #     \"type\":\"image\",\n",
    "                            #     \"data_type\":\"uint8\"\n",
    "                            # }\n",
    "                        },\n",
    "                        # \"bucket_name\": bucket_name   \n",
    "                    }\n",
    "    \n",
    "    return task_definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a task per tissue sample collection using the defined collab name, bucket_name, regex filter and source location.\n",
    "for task_num in range(len(tsc_data)):\n",
    "\n",
    "    task_definition = build_task(tsc_data.repository[task_num], tsc_data.regex_pattern[task_num], tsc_data.collab_name[task_num])\n",
    "    fname = os.path.join(output_path, \"task_\" + tsc_data.tsc_name[task_num] + \".json\")\n",
    "    with open(fname, 'w', encoding='utf-8') as fi:\n",
    "        fi.write(json.dumps(task_definition, ensure_ascii=False, indent=4))\n",
    "\n",
    "print(\"Task definitions have been created\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65747024ff2feda9d45d54fef14313a73f026ac80ef7ca2f452fcc1ca90b45f3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
