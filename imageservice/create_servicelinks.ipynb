{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating service links and linking them to file bundles\n",
    "\n",
    "With this notebook you can do the following:\n",
    "1. Load CSV file with the tissue sample collection metadata (script \"extract_tsc_info.ipynb\") and the URL links for the viewer.\n",
    "2. Create URL instances in the KGE\n",
    "3. Create service links and link the correct file bundle to the correct URL instance\n",
    "4. Post the newly created instances to the KGE\n",
    "\n",
    "To be able to run the script, you need to the following requirements:\n",
    "- Python version >= 3.6\n",
    "- openMINDS package (can be downloaded from https://pypi.org/project/openMINDS/)\n",
    "- read and write permission to the KG via the API\n",
    "\n",
    "Information about the URL links should be stored in a .csv file with the following column names written in the correct way. **Note that more columns can be present in the csv file. They will not be used and do not affect the script.**: \n",
    "- sub_name\n",
    "- tsc_name\n",
    "- tsc_internalID\n",
    "- fileBundle_name\n",
    "- fileBundle_uuid\n",
    "- viewer_link\n",
    "\n",
    "The subject and the internal identifier of the tissue sample collection will be used to generate a label for the service link, which can be found under the \"view data\" tab on the dataset card. The convention for this is as follows: \"tissue sample collection <tsc_internalID> (subject <sub_name)>\". The viewer_link and the uuid of the file bundle is used link the file bundle to the service link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "from getpass import getpass\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import openMINDS\n",
    "import openMINDS.version_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metadata\n",
    "\n",
    "To load the metadata stored in the CSV file, we first define the location where the file is stored and the name of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the script in the same folder as the csv file or define Location of the files\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Load information for the service links\n",
    "dsv_uuid = input(\"What is the UUID of the dataset? \")\n",
    "filename = \"tsc_\" + dsv_uuid + \".csv\"\n",
    "\n",
    "answer = input(\"Is this where your files are stored: \" + os.path.join(cwd, dsv_uuid) + \"? yes (y) or no (n) \" ) \n",
    "\n",
    "if answer == \"y\":\n",
    "    fpath = os.path.join(cwd, dsv_uuid)\n",
    "elif answer == \"n\":\n",
    "    fpath = input(\"Please define you path: \")\n",
    "\n",
    "kg_prefix = \"https://kg.ebrains.eu/api/instances/\"\n",
    "\n",
    "output_path = os.path.join(fpath, \"\")\n",
    "\n",
    "print(\"Output folder is: \" + output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file and print the first few rows to check\n",
    "df = pd.read_csv(os.path.join(output_path,filename))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create instances for the URL and service links\n",
    "\n",
    "To create instances that are conform with openMINDS, we make use of the openMINDS python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the local copy of openMINDS\n",
    "openMINDS.version_manager.init()\n",
    "openMINDS.version_manager.version_selection('v3')\n",
    "helper = openMINDS.Helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create URL instances and service link instances\n",
    "def createInstances(df): \n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame with information to create URL and service link instances\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pandas DataFrame\n",
    "        Overview of all information and newly created instances.\n",
    "\n",
    "    \"\"\"\n",
    "    # Check first if subject names were entered.\n",
    "    if not 'sub_name' in df:\n",
    "        print(\"Column 'sub_name' does not exist in the csv file. Please include this column and define the subject names!\")\n",
    "        return\n",
    "\n",
    "    # Ask the service the service links should be opened in.\n",
    "    answer = input(\"Should the link be opened in 1) LocaliZoom, 2) Siibra-explorer or 3) Multi-Image-OSd: \")\n",
    "    if answer == \"1\":\n",
    "        service_atid = \"https://openminds.ebrains.eu/instances/service/LocaliZoom\"\n",
    "    elif answer == \"2\":\n",
    "        service_atid = \"https://openminds.ebrains.eu/instances/service/siibraExplorer\"\n",
    "    elif answer == \"3\":\n",
    "        service_atid = \"https://openminds.ebrains.eu/instances/service/Multi-Image-OSd\"\n",
    "    \n",
    "    #fileBundles = df.fileBundle.unique()\n",
    "    link_dict = {}\n",
    "    url_dict = {}\n",
    "    data = pd.DataFrame([])\n",
    "    for sample_num in range(len(df.tsc_internalID)):\n",
    "   \n",
    "\n",
    "        print(\"Creating URL for subject \" + str(df.sub_name[sample_num]) + \" with tissue sample collection \" + str(df.tsc_internalID[sample_num]) + \"\\n\")\n",
    "\n",
    "        # initiate the collection into which you will store all metadata instances\n",
    "        mycol = helper.create_collection()\n",
    "        \n",
    "        # Create URL link \n",
    "        url_dict[df.fileBundle_name[sample_num]] = mycol.add_core_URL(URL = df.viewer_link[sample_num])\n",
    "        \n",
    "        print(\"Creating service link for subject \" + str(df.sub_name[sample_num]) + \" with file bundle \" + str(df.fileBundle_name[sample_num]) + \"\\n\")\n",
    "    \n",
    "        # Create Service link    \n",
    "        link_dict[df.fileBundle_name[sample_num]] = mycol.add_core_serviceLink(\n",
    "            dataLocation = [{\"@id\": kg_prefix + df.fileBundle_uuid[sample_num]}],\n",
    "            openDataIn = [{\"@id\": kg_prefix + url_dict[df.fileBundle_name[sample_num]].split(\"/\")[-1]}],\n",
    "            service = [{\"@id\": service_atid}]) \n",
    "        if  pd.isnull(df.sub_name[sample_num]) and pd.isnull(df.tsc_internalID):\n",
    "            label = \"tissue sample collection (subject \" + str(df.fileBundle_name[sample_num]) + \")\"\n",
    "        elif str(df.sub_name[sample_num]) in str(df.tsc_internalID[sample_num]):\n",
    "            if str(df.sub_name[sample_num]) == str(df.tsc_internalID[sample_num]):\n",
    "                label = \"tissue sample collection (subject \" + str(df.sub_name[sample_num]) + \")\"\n",
    "            else:\n",
    "                new_tsc_name = str(df.tsc_internalID[sample_num]).replace(str(df.sub_name[sample_num]),\"\").lstrip(\"_\")\n",
    "                label = \"tissue sample collection \" + str(new_tsc_name) + \" (subject \" + str(df.sub_name[sample_num]) + \")\"\n",
    "        mycol.get(link_dict[df.fileBundle_name[sample_num]]).name = label\n",
    "    \n",
    "        data = data.append(pd.DataFrame({\"subject_name\" : df.sub_name[sample_num],\n",
    "                    \"tsc_name\" : df.tsc_internalID[sample_num],\n",
    "                    \"fileBundle_name\" : df.fileBundle_name[sample_num],  \n",
    "                    \"viewer_link\" : df.viewer_link[sample_num],\n",
    "                    \"viewerLink_uuid\" : url_dict[df.fileBundle_name[sample_num]].split(\"/\")[-1],\n",
    "                    \"ServiceLink_uuid\" : link_dict[df.fileBundle_name[sample_num]].split(\"/\")[-1],\n",
    "                    \"ServiceLink_dataLocation_uuid\" : df.fileBundle_uuid[sample_num],\n",
    "                    \"ServiceLink_name\" : label,\n",
    "                    \"ServiceLink_service_atid\" : service_atid},                \n",
    "                            index=[0]), ignore_index=True)\n",
    "    \n",
    "        mycol.save(os.path.join(output_path, \"\"))  \n",
    "    \n",
    "    print(\"Done! Instance are created and saved in the output folder!\")\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the instances can be created, please select which service/viewer the URLs need to be opened in.\n",
    "Select:\n",
    "1. LocaliZoom\n",
    "2. Siibra-explorer\n",
    "3. Multi-Image-OSd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances and save them    \n",
    "data = createInstances(df)\n",
    "\n",
    "if data.empty:\n",
    "    print(\"No data loaded, please try again\")\n",
    "else:\n",
    "    savedInstances = os.path.join(output_path, \"instances_\" + dsv_uuid + \".csv\")\n",
    "    data.to_csv(savedInstances, index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "To be able to upload the newly created instances directly to the Knowledge Graph editor via the API, you need an access token. To request a token, follow this link: https://nexus-iam.humanbrainproject.org/v0/oauth2/authorize or copy your token from the Knowledge Graph Editor (if you have access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = getpass(prompt='Please paste your token: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload instances to the Knowledge Graph editor\n",
    "\n",
    "We first define the function to upload data to the KGE and then we execute the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload the instances to the KGE\n",
    "def upload(instances_fnames, token, space_name):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    instances_fnames : List \n",
    "        list of file paths to instances that need to be uploaded\n",
    "    token : string\n",
    "        Authorisation token to get access to the KGE\n",
    "    space_name : string\n",
    "        Space that the instances needs to be uploaded to, e.g. \"dataset\", \"common\", etc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    response : dictionary\n",
    "        For each UUID as response is stored that indications if the upload \n",
    "        was successful\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    hed = {\"accept\": \"*/*\",\n",
    "           \"Authorization\": \"Bearer \" + token,\n",
    "           \"Content-Type\": \"application/json\"\n",
    "           }\n",
    "    \n",
    "    # Prefix to upload to the right space\n",
    "    url = \"https://core.kg.ebrains.eu/v3-beta/instances/{}?space=\" + space_name\n",
    "    kg_prefix = \"https://kg.ebrains.eu/api/instances/\"\n",
    "    \n",
    "    new_instances = []\n",
    "    for fname in instances_fnames:\n",
    "        with open(fname, 'r') as f:\n",
    "            new_instances.append(json.load(f))\n",
    "        f.close()\n",
    "    \n",
    "    # Correct the capitalisation in the openMINDS package\n",
    "    for instance in new_instances:\n",
    "        atid = kg_prefix + instance[\"@id\"].split(\"/\")[-1] #only take the UUID \n",
    "        instance[\"@id\"] = atid\n",
    "        if \"openDataIn\" in instance.keys():\n",
    "            atid = kg_prefix + instance[\"openDataIn\"][0][\"@id\"].split(\"/\")[-1] #only take the UUID \n",
    "            instance[\"openDataIn\"][0][\"@id\"] = atid\n",
    "        if instance[\"@type\"].endswith(\"Servicelink\"):\n",
    "            splittype = instance[\"@type\"].split(\"/\")[:-1]\n",
    "            splittype.append(\"ServiceLink\")\n",
    "            instance[\"@type\"] = \"/\".join(splittype)\n",
    "        if instance[\"@type\"].endswith(\"Url\"):\n",
    "            splittype = instance[\"@type\"].split(\"/\")[:-1]\n",
    "            splittype.append(\"URL\")\n",
    "            instance[\"@type\"] = \"/\".join(splittype)\n",
    "    \n",
    "    # Upload to the KGE\n",
    "    print(\"\\nUploading instances now:\\n\")\n",
    "    \n",
    "    count = 0\n",
    "    response = {}    \n",
    "    for instance in new_instances:\n",
    "        count += 1\n",
    "        print(\"Posting instance \" + str(count)+\"/\"+str(len(new_instances)))\n",
    "        atid = instance[\"@id\"].split(\"/\")[-1] \n",
    "        response[atid] = requests.post(url.format(atid), json=instance, headers=hed)\n",
    "        if response[atid].status_code == 200:\n",
    "            print(response[atid], \"OK!\" )\n",
    "        elif response[atid].status_code == 409:\n",
    "            print(response[atid], \"Instance already exists\")\n",
    "        elif response[atid].status_code == 401:\n",
    "            print(response[atid], \"Token not valid, authorisation not successful\")\n",
    "        else:\n",
    "            print(response[atid])\n",
    "        \n",
    "        \n",
    "    return response  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload instances to the KGE\n",
    "answer = input(\"Would you like to upload the instances you created to the KGE? yes (y) or no (n) \" ) \n",
    "\n",
    "if answer == \"y\":\n",
    "    instances_fnames = glob.glob(os.path.join(output_path, \"\") + \"*\\\\*\", recursive = True)\n",
    "\n",
    "    print(\"\\nUploading data now:\\n\")\n",
    "    \n",
    "    if token != \"\":\n",
    "        response = upload(instances_fnames, token, space_name = \"dataset\")  \n",
    "        \n",
    "elif answer == \"n\":\n",
    "    print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "65747024ff2feda9d45d54fef14313a73f026ac80ef7ca2f452fcc1ca90b45f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
